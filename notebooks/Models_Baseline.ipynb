{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions with Fully Convolutional Networks\n",
    "Instead of using purely traditional computer vision methods, I use Deep Learning as it has shown to match or even exceed previous state-of-the-art methods. \n",
    "\n",
    "![unet](resources/unet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7811,
     "status": "ok",
     "timestamp": 1522481659316,
     "user": {
      "displayName": "Kenny Kang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100936701342634082666"
     },
     "user_tz": 420
    },
    "id": "KdobJHZdeVY4",
    "outputId": "a5d6dc15-925a-4c0a-fa72-8dd408ab9e67"
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "import pickle\n",
    "import imageio\n",
    "\n",
    "# Dependencies for Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.measure import label\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from tensorflow import set_random_seed\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8pV5iuflqJq-"
   },
   "outputs": [],
   "source": [
    "DATA_SPLIT = 650\n",
    "IMAGE_MEAN = 0.17166166804067506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pickle.load(open('../processed_data/gray_train_X.p', 'rb'))\n",
    "labels = pickle.load(open('../processed_data/train_Y_baseline.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted labels\n",
    "labels = pickle.load(open('../processed_data/weighted_train_masks.p', 'rb'))\n",
    "weights = pickle.load(open('../processed_data/weighted_train_weights.p', 'rb'))\n",
    "weights = np.expand_dims(weights, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Split\n",
    "Since the amount of training data is limited ( < 1000), I only used a training and test set instead of also including a validation set. While this does sacrifice the ability to create a more robust model, the greater number of samples will reduce the overall variance of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.expand_dims(labels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "output_extras": [
      {
       "item_id": 10
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8258,
     "status": "ok",
     "timestamp": 1521774303419,
     "user": {
      "displayName": "Kenny Kang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100936701342634082666"
     },
     "user_tz": 420
    },
    "id": "2-kTCqTeHk2U",
    "outputId": "76c85aaa-f72d-47e0-96c4-2dcca28a5446"
   },
   "outputs": [],
   "source": [
    "train_X = images[:DATA_SPLIT,:,:,:] - IMAGE_MEAN\n",
    "train_Y = labels[:DATA_SPLIT,:,:,:] #Reduced range to [0,1]\n",
    "\n",
    "valid_X = images[DATA_SPLIT:,:,:,:] - IMAGE_MEAN\n",
    "valid_Y = labels[DATA_SPLIT:,:,:,:] #Reduced range to [0,1]\n",
    "\n",
    "train_Y_w = labels[:DATA_SPLIT,:,:,:] #Reduced range to [0,1]\n",
    "train_weights_w = weights[:DATA_SPLIT,:,:,:] #Reduced range to [0,1]\n",
    "valid_weights_w = images[DATA_SPLIT:,:,:,:]\n",
    "# train_weights_w = np.reshape(train_weights_w, (256,256,1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DEuZQCR0qpHB"
   },
   "source": [
    "# U-Net\n",
    "Based on this paper: [U-Net: Convolutional Networks for Biomedical\n",
    "Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LSwtTKxP6qAw"
   },
   "outputs": [],
   "source": [
    "model = Unet_Vanilla()\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train([train_X], [train_Y], batch_size = 32, epochs = 100, validation_data=(valid_X, valid_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net w/ Pretrained Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet_VGG16()\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train([train_X], [train_Y], batch_size = 32, epochs = 100, validation_data=(valid_X, valid_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.unfreeze_encoder(optimizer=optimizers.Adam(0.0003))\n",
    "model.train([train_X], [train_Y], batch_size = 32, epochs = 100, validation_data=(valid_X, valid_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Unet_VGG16_Weighted()\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x=[train_X,train_weights_w], y=[train_Y], batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unfreeze_encoder(optimizer=optimizers.Adam(0.0003))\n",
    "model.train(x=[train_X,train_weights_w], y=[train_Y], batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VNVBDiexBqJk"
   },
   "source": [
    "# Make Predictions with Trained Model\n",
    "In order to measure the accuracy of the model, I used a Intersection over Union (IOU) metric which utilizes the area of interection between the ground truth and the predicted mask, and compares it to the total area covered by the union of the two.\n",
    "\n",
    "![iou](resources/iou_image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pickle.load(open('../processed_data/train_Y_baseline.p', 'rb'))\n",
    "labels = np.expand_dims(labels, axis=-1)\n",
    "valid_Y = labels[DATA_SPLIT:,:,:,:] #Reduced range to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tabVxHVBkVmk"
   },
   "outputs": [],
   "source": [
    "  # Predict Validation Data\n",
    "pred = model2.predict([valid_X, np.zeros(shape=(len(valid_X),256,256,1))])\n",
    "print(np.mean(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Predict Validation Data\n",
    "pred = model2.predict(valid_X)\n",
    "print(np.mean(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 363,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1206,
     "status": "ok",
     "timestamp": 1522469130267,
     "user": {
      "displayName": "Kenny Kang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100936701342634082666"
     },
     "user_tz": 420
    },
    "id": "zH3hf2elwo-j",
    "outputId": "2599c1af-b78c-44c1-88df-e93875e2ade0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample = 1\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=2)\n",
    "\n",
    "pred_rounded = np.where(pred[sample,:,:,0] > 0.99, 1, 0)\n",
    "ax[0,0].imshow(valid_X[sample,:,:,:])\n",
    "ax[0,1].imshow(valid_Y[sample,:,:,0])\n",
    "ax[1,0].imshow(pred[sample,:,:,0])\n",
    "ax[1,1].imshow(pred_rounded)\n",
    "np.amax(pred[sample,:,:,0])\n",
    "# pred[sample,:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = label(y_true_in == 1)\n",
    "    y_pred = label(y_pred_in > 0.999)\n",
    "    \n",
    "    true_objects = len(np.unique(labels))\n",
    "    pred_objects = len(np.unique(y_pred))\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = len(y_true_in)\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "#     return np.array(np.mean(metric), dtype=np.float32)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_Y[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_metric(valid_Y[:,:,:,0], pred[:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((10,10),np.uint8)\n",
    "pred = pred.reshape(-1,256,256)\n",
    "for i in range(len(pred)):\n",
    "    pred[i] = cv2.morphologyEx(pred[i], cv2.MORPH_CLOSE, kernel)\n",
    "pred = pred.reshape(-1,256,256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[4][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Clusters\n",
    "The output of the Fully Convolutional Network, while outputting a relatively accurate mask, fails to separate clusters of nuclei into individual instances. One option to solve this is to utilize traditional computer vision methods. One such method is Watershed which essentially shrinks images around points which are guaranteed to be the foreground, or part of the nuclei. An example of this is shown below:\n",
    "\n",
    "![watershed](resources/watershed.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_watershed(pred):\n",
    "    watershed_pred = []\n",
    "    for i in range(len(pred)):\n",
    "        image = pred[i,:,:,0] > 0.999\n",
    "        \n",
    "        \n",
    "        distance = ndi.distance_transform_edt(image)\n",
    "        local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((2, 2)),\n",
    "                            labels=image)\n",
    "        markers = ndi.label(local_maxi)[0]\n",
    "        labels = watershed(-distance, markers, mask=image)\n",
    "       \n",
    "        watershed_pred.append(labels)\n",
    "        \n",
    "    watershed_pred = np.stack(watershed_pred, axis=0)\n",
    "    return watershed_pred\n",
    "\n",
    "watershed_pred = apply_watershed(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_metric(valid_Y[:,:,:,0], watershed_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(np.where(watershed_pred[0] >= 1, 1 ,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(valid_Y[2,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(watershed_pred[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(watershed_pred[0] - np.where(pred[0,:,:,0] > 0.55, 1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(valid_Y[1,:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(np.where(pred[1,:,:,0] > 0.55, 1,0))\n",
    "plt.figure()\n",
    "plt.imshow(watershed_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_raYhzCriSz"
   },
   "source": [
    "## Methods for Saving/Loading Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8_5rHCEro-M"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "output_extras": [
      {
       "item_id": 8
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10995,
     "status": "ok",
     "timestamp": 1522468842291,
     "user": {
      "displayName": "Kenny Kang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100936701342634082666"
     },
     "user_tz": 420
    },
    "id": "wUZyvOoXwtfo",
    "outputId": "9834dd8d-bffd-4d81-e3fb-332e148d203d"
   },
   "outputs": [],
   "source": [
    "#SAVE MODEL\n",
    "\n",
    "model2.save('../unet_gray.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtd7roGfrrCD"
   },
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 10
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13126,
     "status": "ok",
     "timestamp": 1522481718385,
     "user": {
      "displayName": "Kenny Kang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100936701342634082666"
     },
     "user_tz": 420
    },
    "id": "CjQ0Jpl13NHQ",
    "outputId": "677990cd-06e3-4528-ad02-e15750cf19c5"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "# model = load_model('unet_baseline.h5', custom_objects={'weighted_binary_crossentropy_loss': weighted_binary_crossentropy_loss, 'mean_iou': mean_iou})\n",
    "model2 = load_model('../unet.h5', custom_objects={'weighted_binary_crossentropy_loss': weighted_binary_crossentropy_loss, 'mean_iou': mean_iou})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFAC0n82J8tG"
   },
   "source": [
    "## Use Test Data\n",
    "Using the final pipeline, I predicted the masks for the test class, resized them to the original dimensions, and format the results into a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jBmOoZcbKVCN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_images = pickle.load(open('../processed_data/test_X.p', 'rb'))\n",
    "##test_images2 = pickle.load(open('test_X_baseline2.p', 'rb'))\n",
    "\n",
    "##test_images = np.concatenate([test_images1, test_images2], axis=0) \n",
    "\n",
    "# test_sizes = pickle.load(open('../test_sizes.p', 'rb'))\n",
    "# test_ids = pickle.load(open('../test_img_names.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1522469162209,
     "user": {
      "displayName": "Kenny Kang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100936701342634082666"
     },
     "user_tz": 420
    },
    "id": "XOxY5P2uyn6F",
    "outputId": "08fa85f2-e1ed-4e4d-f3c3-f08f9a3d0650"
   },
   "outputs": [],
   "source": [
    "model = model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aAcnUEpqKDPB"
   },
   "outputs": [],
   "source": [
    "test_images = test_images - IMAGE_MEAN\n",
    "pred = model.predict(test_images)\n",
    "# watershed_pred = apply_watershed(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(test_images[sample,:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(pred[sample,:,:,0])\n",
    "mask2 = np.where(pred[sample,:,:,0] > 0.999, 1, 0)\n",
    "plt.figure()\n",
    "plt.imshow(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(test_sizes)):\n",
    "    preds.append(imresize(watershed_pred[i],test_sizes[i][:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(preds[0][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AQIlwLQrKbzV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hvE0QLe6KgLQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def regex(txt):\n",
    "\n",
    "  re1 = '(?:[a-z0-9][a-z]*[0-9]+[a-z0-9]*)/'\n",
    "\n",
    "  rg = re.compile(re1)\n",
    "  m = rg.search(txt)\n",
    "  if m:\n",
    "      alphanum1=m.group(0)\n",
    "  return alphanum1[0:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 456,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1522469183514,
     "user": {
      "displayName": "Kenny Kang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "100936701342634082666"
     },
     "user_tz": 420
    },
    "id": "j4kbs8MHVvIP",
    "outputId": "e71404cc-b93b-4c94-83f6-8566d9467697",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = 2\n",
    "shape = test_sizes[sample]\n",
    "shape = (shape[0],shape[1])\n",
    "mask = imresize(pred[sample,:,:,0], shape) / 255\n",
    "mask2 = label(np.where(mask > 0.9, 1, 0),connectivity=2)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=3)\n",
    "\n",
    "ax[0,0].imshow(test_images[sample])\n",
    "ax[0,1].imshow(mask)\n",
    "ax[0,2].imshow(mask2)\n",
    "\n",
    "print(test_images[sample].shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Masks\n",
    "from scipy import ndimage\n",
    "labels, nlabels = ndimage.label(watershed[0])\n",
    "\n",
    "label_arrays = []\n",
    "for label_num in range(1, nlabels+1):\n",
    "    label_mask = np.where(labels == label_num, 1, 0)\n",
    "    label_arrays.append(label_mask)\n",
    "\n",
    "print('There are {} separate components / objects detected.'.format(nlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encoding(x):\n",
    "    '''\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run length as list\n",
    "    '''\n",
    "    dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b+1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cut_off = 0.5):\n",
    "    lab_img = label(x>cut_off)\n",
    "    if lab_img.max()<1:\n",
    "        lab_img[0,0] = 1 # ensure at least one prediction per image\n",
    "    for i in range(1, lab_img.max()+1):\n",
    "        yield rle_encoding(lab_img==i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "count = 0\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds[n]))\n",
    "    \n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_[:-4] for i in range(len(rle))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub[['ImageId', 'EncodedPixels']].to_csv('baseline_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PnDyiJA503G4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"stage2_sample_submission_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = sorted(zip(new_test_ids, rles))\n",
    "new_test_ids = []\n",
    "rles = []\n",
    "for x,y in solution:\n",
    "    new_test_ids.append(x)\n",
    "\n",
    "    rles.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('baseline_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub.ImageId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "kaggle-nuclei.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning]",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
